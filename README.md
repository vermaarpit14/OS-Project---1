# Parallel Prime Number Computation Benchmark

This project explores **parallel computation using multiple processes**
to efficiently find prime numbers within large numeric ranges.\
It benchmarks performance, analyzes scalability, and visualizes results
using graphs.

The goal is to understand how **execution time varies with the number of
child processes** and how it scales with increasing workload.

------------------------------------------------------------------------

## Motivation

Prime number computation is a **CPU-intensive task**.\
By dividing the workload among multiple processes, we can utilize modern
multi-core processors more effectively.

This project demonstrates: - Practical use of `fork()` in Linux -
Real-world performance benchmarking - Effects of over-parallelization -
Visualization of performance trends

------------------------------------------------------------------------

## Project Components

### 1. C Program --- `fastprime.c`

-   Uses **multiple child processes** via `fork()`
-   Splits the input range evenly across processes
-   Each process independently computes primes in its assigned chunk
-   All results are appended to a shared file (`prime.txt`)
-   Execution time is measured using `gettimeofday()`
-   Graceful termination using `SIGINT` (Ctrl+C)

### 2. Python Script --- `benchmark.py`

-   Compiles the C program automatically
-   Detects the number of logical CPU cores
-   Executes the program with varying process counts
-   Collects execution times
-   Generates performance graphs using Matplotlib

------------------------------------------------------------------------

## Repository Structure

``` text
.
├── fastprime.c              # Parallel prime computation (C)
├── benchmark.py             # Benchmark runner and plot generator
├── prime.txt                # Output file containing prime numbers
├── execution_time_plot.png  # Performance graph
└── README.md
```

------------------------------------------------------------------------

## Compilation

Ensure GCC is installed on your system.

``` bash
gcc fastprime.c -o fastprime -lm
```

------------------------------------------------------------------------

## Usage

### Running the Prime Computation

``` bash
./fastprime <range_low> <range_high> <num_processes>
```

Example:

``` bash
./fastprime 1000 100000 4
```

Output:

``` text
0.023456
```

(The printed value represents execution time in seconds.)

------------------------------------------------------------------------

## Benchmarking and Visualization

Run the Python benchmark script:

``` bash
python3 benchmark.py
```

This will: - Compile the C program - Run experiments for multiple
numeric ranges - Vary the number of processes from 1 up to (CPU cores +
2) - Generate a performance graph

------------------------------------------------------------------------

## Python Dependency Setup

Modern Linux distributions restrict system-wide pip installs (PEP 668).

### Recommended: Virtual Environment

``` bash
sudo apt install python3-venv python3-full
python3 -m venv venv
source venv/bin/activate
pip install matplotlib
python benchmark.py
```

### Alternative: System Package

``` bash
sudo apt install python3-matplotlib
python3 benchmark.py
```

------------------------------------------------------------------------

## Sample Execution Time Graph

Below is a sample performance graph generated by this project:

![Execution Time vs Number of Processes](execution_time_plot.png)

------------------------------------------------------------------------

## Graph Explanation

-   **X-axis**: Number of child processes\
-   **Y-axis**: Execution time (seconds)\
-   Each curve represents a different numeric range\
-   Initial speedup is observed as processes increase\
-   Performance plateaus or degrades due to:
    -   Process creation overhead
    -   CPU scheduling contention
    -   File I/O bottlenecks

------------------------------------------------------------------------

## Benchmark Ranges Used

-   1,000 -- 10,000
-   50,000 -- 100,000
-   100,000 -- 500,000

Larger ranges show better scalability due to higher
computation-to-overhead ratio.

------------------------------------------------------------------------

## Key Concepts Demonstrated

-   Process creation using `fork()`
-   Process synchronization using `wait()`
-   Signal handling using `SIGINT`
-   Workload partitioning
-   Buffered file I/O
-   Parallel performance analysis
-   Scalability limits of multiprocessing

------------------------------------------------------------------------

## Observations

-   Optimal performance is achieved near the number of logical CPU cores
-   Increasing processes beyond CPU cores may increase execution time
-   File writes are buffered to reduce system call overhead
-   Parallelism benefits grow with problem size

------------------------------------------------------------------------

## System Requirements

### C

-   Linux / WSL
-   GCC compiler

### Python

-   Python 3.x
-   Matplotlib

------------------------------------------------------------------------

## Authors


PALURI VEERA DURGA VARA PRASAD	24CS8031	
GOGULAMUDI PREM SANTHOSH	24CS8032	
PRADIP GORAI	24CS8033	
GUNTREDDI NEELAPRASANTH	24CS8034	
DARLA POOJITHA	24CS8035	
ANJALI SINGH	24CS8036
ANIKET HALDAR	24CS8037	
ARPIT VERMA	24CS8038	
HIMANSHU GUPTA	24CS8039	
RAJ GURU        24CS8040

------------------------------------------------------------------------

## Conclusion

This project provides a practical understanding of **process-based
parallelism in Linux**, highlighting both its advantages and
limitations.\
It connects operating system concepts with real performance measurements
and visualization.